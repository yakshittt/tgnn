{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14788006,"sourceType":"datasetVersion","datasetId":9453958},{"sourceId":14811156,"sourceType":"datasetVersion","datasetId":9471174}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ======================================================\n# FINAL MEMORY-SAFE SPATIO-TEMPORAL TGNN\n# Proper Temporal Split + Chunked Training\n# ======================================================\n\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.metrics import precision_recall_curve, auc\n\n# ---------------- CONFIG ----------------\nDATA_DIR = \"/kaggle/input/firms-01\"\nEPOCHS = 10\nLR = 1e-3\nTRAIN_SPLIT = 0.8\nCHUNK = 14  # Temporal chunk size (Truncated BPTT)\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(\"Using device:\", DEVICE)\nprint(\"=\" * 60)\n\n\n# ======================================================\n# LOAD TILE SEQUENCES\n# ======================================================\n\ntiles = []\n\nfor fname in sorted(os.listdir(DATA_DIR)):\n    if fname.endswith(\".npz\"):\n        path = os.path.join(DATA_DIR, fname)\n        data = np.load(path)\n\n        X = torch.tensor(data[\"X\"], dtype=torch.float32)\n        y = torch.tensor(data[\"y\"], dtype=torch.float32)\n        edge_index = torch.tensor(data[\"edge_index\"], dtype=torch.long)\n\n        tiles.append((X, y, edge_index))\n\nprint(\"Total tiles:\", len(tiles))\n\n\n# ======================================================\n# GRAPH CONV\n# ======================================================\n\nclass GraphConv(nn.Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x, edge_index):\n        row, col = edge_index\n        agg = torch.zeros_like(x)\n        agg.index_add_(0, row, x[col])\n        return self.linear(x + agg)\n\n\n# ======================================================\n# TGNN MODEL\n# ======================================================\n\nclass TGNN(nn.Module):\n    def __init__(self,\n                 node_features=6,\n                 hidden_dim=32,\n                 gru_hidden_dim=64,\n                 num_gnn_layers=2):\n        super().__init__()\n\n        self.input_proj = nn.Linear(node_features, hidden_dim)\n\n        self.gnn_layers = nn.ModuleList(\n            [GraphConv(hidden_dim, hidden_dim)\n             for _ in range(num_gnn_layers)]\n        )\n\n        self.batch_norms = nn.ModuleList(\n            [nn.BatchNorm1d(hidden_dim)\n             for _ in range(num_gnn_layers)]\n        )\n\n        self.gru = nn.GRU(\n            input_size=hidden_dim,\n            hidden_size=gru_hidden_dim,\n            num_layers=1,\n            batch_first=True\n        )\n\n        self.fc = nn.Linear(gru_hidden_dim, 1)\n\n    def forward(self, X_seq, edge_index, hidden=None):\n\n        T, N, _ = X_seq.shape\n        spatial_outputs = []\n\n        for t in range(T):\n            x = X_seq[t]\n\n            x = F.relu(self.input_proj(x))\n\n            for conv, bn in zip(self.gnn_layers, self.batch_norms):\n                x = F.relu(bn(conv(x, edge_index)))\n\n            spatial_outputs.append(x)\n\n        H = torch.stack(spatial_outputs)     # (T, N, hidden)\n        H = H.permute(1, 0, 2)               # (N, T, hidden)\n\n        gru_out, hidden = self.gru(H, hidden)\n\n        logits = self.fc(gru_out).squeeze(-1)  # (N, T)\n        logits = logits.permute(1, 0)          # (T, N)\n\n        return logits, hidden\n\n\n# ======================================================\n# CLASS IMBALANCE COMPUTATION\n# ======================================================\n\nall_labels = []\n\nfor X_seq, y_seq, _ in tiles:\n    all_labels.append(y_seq.reshape(-1))\n\nall_labels = torch.cat(all_labels)\npos_ratio = all_labels.mean().item()\n\nprint(\"Positive ratio:\", pos_ratio)\n\npos_weight = torch.tensor([(1 - pos_ratio) / pos_ratio]).to(DEVICE)\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n\n\n# ======================================================\n# MODEL & OPTIMIZER\n# ======================================================\n\nmodel = TGNN().to(DEVICE)\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\n\n# ======================================================\n# TRAINING LOOP (Tile-by-Tile)\n# ======================================================\n\nbest_val_loss = float('inf')\n\nfor epoch in range(EPOCHS):\n\n    model.train()\n    train_loss = 0\n\n    for X_seq, y_seq, edge_index in tiles:\n\n        X_seq = X_seq.to(DEVICE)\n        y_seq = y_seq.to(DEVICE)\n        edge_index = edge_index.to(DEVICE)\n\n        # -------- Temporal Split (NO LEAKAGE) --------\n        T = X_seq.shape[0]\n        split = int(TRAIN_SPLIT * T)\n\n        X_train = X_seq[:split]\n        y_train = y_seq[:split]\n\n        X_val = X_seq[split:]\n        y_val = y_seq[split:]\n\n        hidden = None\n        optimizer.zero_grad()\n        total_loss = 0\n\n        # -------- Truncated BPTT --------\n        for t in range(0, X_train.shape[0], CHUNK):\n\n            X_chunk = X_train[t:t+CHUNK]\n            y_chunk = y_train[t:t+CHUNK]\n\n            logits, hidden = model(X_chunk, edge_index, hidden)\n\n            loss = criterion(\n                logits.reshape(-1),\n                y_chunk.reshape(-1)\n            )\n\n            loss.backward()\n            hidden = hidden.detach()\n\n            total_loss += loss.item()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n        train_loss += total_loss\n\n    train_loss /= len(tiles)\n\n    # ======================================================\n    # VALIDATION\n    # ======================================================\n\n    model.eval()\n    val_loss = 0\n    all_preds = []\n    all_targets = []\n\n    with torch.no_grad():\n\n        for X_seq, y_seq, edge_index in tiles:\n\n            X_seq = X_seq.to(DEVICE)\n            y_seq = y_seq.to(DEVICE)\n            edge_index = edge_index.to(DEVICE)\n\n            T = X_seq.shape[0]\n            split = int(TRAIN_SPLIT * T)\n\n            X_val = X_seq[split:]\n            y_val = y_seq[split:]\n\n            hidden = None\n\n            for t in range(0, X_val.shape[0], CHUNK):\n\n                X_chunk = X_val[t:t+CHUNK]\n                y_chunk = y_val[t:t+CHUNK]\n\n                logits, hidden = model(X_chunk, edge_index, hidden)\n\n                loss = criterion(\n                    logits.reshape(-1),\n                    y_chunk.reshape(-1)\n                )\n\n                val_loss += loss.item()\n\n                probs = torch.sigmoid(logits)\n                all_preds.append(probs.cpu().numpy().reshape(-1))\n                all_targets.append(y_chunk.cpu().numpy().reshape(-1))\n\n                hidden = hidden.detach()\n\n    val_loss /= len(tiles)\n\n    all_preds = np.concatenate(all_preds)\n    all_targets = np.concatenate(all_targets)\n\n    precision, recall, _ = precision_recall_curve(all_targets, all_preds)\n    pr_auc = auc(recall, precision)\n\n    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n    print(f\"Train Loss: {train_loss:.4f}\")\n    print(f\"Val Loss:   {val_loss:.4f}\")\n    print(f\"Val PR-AUC: {pr_auc:.4f}\")\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), \"best_tgnn.pt\")\n        print(\"✓ Best model saved\")\n\nprint(\"\\nTraining complete.\")\nprint(\"=\" * 60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T20:20:53.941583Z","iopub.execute_input":"2026-02-11T20:20:53.942381Z","iopub.status.idle":"2026-02-11T20:31:35.785275Z","shell.execute_reply.started":"2026-02-11T20:20:53.942350Z","shell.execute_reply":"2026-02-11T20:31:35.784503Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n============================================================\nTotal tiles: 130\nPositive ratio: 0.004165706690400839\n\nEpoch 1/10\nTrain Loss: 21.1994\nVal Loss:   4.6897\nVal PR-AUC: 0.0110\n✓ Best model saved\n\nEpoch 2/10\nTrain Loss: 14.4351\nVal Loss:   5.0512\nVal PR-AUC: 0.0124\n\nEpoch 3/10\nTrain Loss: 13.7306\nVal Loss:   4.8952\nVal PR-AUC: 0.0133\n\nEpoch 4/10\nTrain Loss: 13.3922\nVal Loss:   4.0714\nVal PR-AUC: 0.0139\n✓ Best model saved\n\nEpoch 5/10\nTrain Loss: 13.1973\nVal Loss:   4.2223\nVal PR-AUC: 0.0116\n\nEpoch 6/10\nTrain Loss: 13.0181\nVal Loss:   4.3511\nVal PR-AUC: 0.0133\n\nEpoch 7/10\nTrain Loss: 12.8538\nVal Loss:   4.2940\nVal PR-AUC: 0.0123\n\nEpoch 8/10\nTrain Loss: 12.7519\nVal Loss:   4.3835\nVal PR-AUC: 0.0126\n\nEpoch 9/10\nTrain Loss: 12.6334\nVal Loss:   4.2684\nVal PR-AUC: 0.0139\n\nEpoch 10/10\nTrain Loss: 12.5690\nVal Loss:   4.4889\nVal PR-AUC: 0.0155\n\nTraining complete.\n============================================================\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ======================================================\n# CORRECTED SPATIO-TEMPORAL TGNN (FIXED SCHEDULER)\n# Proper Tile-Based Split + Memory-Safe Training\n# ======================================================\n\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.metrics import precision_recall_curve, auc, roc_auc_score\n\n# ---------------- CONFIG ----------------\nDATA_DIR = \"/kaggle/input/firms-01\"\nEPOCHS = 10\nLR = 1e-3\nTRAIN_SPLIT = 0.8\nCHUNK = 14  # Truncated BPTT window\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nPATIENCE = 3\n\nprint(\"Using device:\", DEVICE)\nprint(\"=\" * 60)\n\n\n# ======================================================\n# FOCAL LOSS (Better for imbalance)\n# ======================================================\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n    \n    def forward(self, logits, targets):\n        probs = torch.sigmoid(logits)\n        bce_loss = F.binary_cross_entropy_with_logits(\n            logits, targets, reduction='none'\n        )\n        p_t = probs * targets + (1 - probs) * (1 - targets)\n        focal_weight = (1 - p_t) ** self.gamma\n        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n        focal_loss = alpha_t * focal_weight * bce_loss\n        return focal_loss.mean()\n\n\n# ======================================================\n# LOAD TILE SEQUENCES\n# ======================================================\n\nprint(\"\\nLoading tiles...\")\ntiles = []\n\nfor fname in sorted(os.listdir(DATA_DIR)):\n    if fname.endswith(\".npz\"):\n        path = os.path.join(DATA_DIR, fname)\n        data = np.load(path)\n\n        X = torch.tensor(data[\"X\"], dtype=torch.float32)\n        y = torch.tensor(data[\"y\"], dtype=torch.float32)\n        edge_index = torch.tensor(data[\"edge_index\"], dtype=torch.long)\n\n        tiles.append((X, y, edge_index))\n\nprint(f\"Total tiles loaded: {len(tiles)}\")\n\n# ======================================================\n# PROPER TILE-BASED TRAIN/VAL SPLIT (NO LEAKAGE!)\n# ======================================================\n\nsplit_idx = int(TRAIN_SPLIT * len(tiles))\ntrain_tiles = tiles[:split_idx]\nval_tiles = tiles[split_idx:]\n\nprint(f\"\\nDataset split:\")\nprint(f\"  Train tiles: {len(train_tiles)}\")\nprint(f\"  Val tiles:   {len(val_tiles)}\")\n\n# ======================================================\n# ANALYZE CLASS DISTRIBUTION\n# ======================================================\n\nprint(\"\\nAnalyzing class distribution...\")\nall_labels = []\nfor X_seq, y_seq, _ in tiles:\n    all_labels.append(y_seq.reshape(-1))\n\nall_labels = torch.cat(all_labels)\npos_ratio = all_labels.mean().item()\nneg_ratio = 1 - pos_ratio\n\nprint(f\"Positive ratio: {pos_ratio:.4%}\")\nprint(f\"Negative ratio: {neg_ratio:.4%}\")\nprint(f\"Imbalance ratio: {neg_ratio/pos_ratio:.2f}:1\")\n\n\n# ======================================================\n# GRAPH CONV\n# ======================================================\n\nclass GraphConv(nn.Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x, edge_index):\n        row, col = edge_index\n        agg = torch.zeros_like(x)\n        agg.index_add_(0, row, x[col])\n        return self.linear(x + agg)\n\n\n# ======================================================\n# TGNN MODEL\n# ======================================================\n\nclass TGNN(nn.Module):\n    def __init__(self,\n                 node_features=6,\n                 hidden_dim=64,\n                 gru_hidden_dim=128,\n                 num_gnn_layers=2,\n                 dropout=0.3):\n        super().__init__()\n\n        self.hidden_dim = hidden_dim\n        self.gru_hidden_dim = gru_hidden_dim\n\n        self.input_proj = nn.Linear(node_features, hidden_dim)\n\n        self.gnn_layers = nn.ModuleList(\n            [GraphConv(hidden_dim, hidden_dim)\n             for _ in range(num_gnn_layers)]\n        )\n\n        self.batch_norms = nn.ModuleList(\n            [nn.BatchNorm1d(hidden_dim)\n             for _ in range(num_gnn_layers)]\n        )\n\n        self.gru = nn.GRU(\n            input_size=hidden_dim,\n            hidden_size=gru_hidden_dim,\n            num_layers=1,\n            batch_first=True\n        )\n\n        self.fc1 = nn.Linear(gru_hidden_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, 32)\n        self.fc3 = nn.Linear(32, 1)\n        \n        self.dropout = nn.Dropout(dropout)\n\n        self._init_weights()\n\n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n    def forward(self, X_seq, edge_index, hidden=None):\n        \"\"\"\n        Args:\n            X_seq: [T, N, F] - Temporal sequence of node features\n            edge_index: [2, E] - Graph structure\n            hidden: [1, N, H] - GRU hidden state\n        \n        Returns:\n            logits: [T, N] - Predictions for each timestep\n            hidden: [1, N, H] - Updated hidden state\n        \"\"\"\n        T, N, _ = X_seq.shape\n        spatial_outputs = []\n\n        # Spatial processing for each timestep\n        for t in range(T):\n            x = X_seq[t]\n            \n            x = F.relu(self.input_proj(x))\n            x = self.dropout(x)\n\n            # GNN layers with residual connections\n            for i, (conv, bn) in enumerate(zip(self.gnn_layers, self.batch_norms)):\n                residual = x\n                x = conv(x, edge_index)\n                x = bn(x)\n                x = F.relu(x)\n                x = self.dropout(x)\n                \n                if i > 0:\n                    x = x + residual\n\n            spatial_outputs.append(x)\n\n        # Stack temporal dimension\n        H = torch.stack(spatial_outputs)  # [T, N, hidden]\n        H = H.permute(1, 0, 2)            # [N, T, hidden]\n\n        # Initialize hidden state if needed\n        if hidden is None:\n            hidden = torch.zeros(\n                1, N, self.gru_hidden_dim,\n                device=X_seq.device, dtype=X_seq.dtype\n            )\n\n        # Temporal processing with GRU\n        gru_out, hidden = self.gru(H, hidden)\n\n        # Prediction head\n        x = gru_out  # [N, T, gru_hidden_dim]\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)\n        \n        logits = self.fc3(x).squeeze(-1)  # [N, T]\n        logits = logits.permute(1, 0)     # [T, N]\n\n        return logits, hidden\n\n\n# ======================================================\n# TRAINING FUNCTION\n# ======================================================\n\ndef train_epoch(model, tiles, criterion, optimizer, device, chunk_size):\n    \"\"\"Train for one epoch on all tiles\"\"\"\n    model.train()\n    total_loss = 0\n    num_chunks = 0\n\n    for X_seq, y_seq, edge_index in tiles:\n        X_seq = X_seq.to(device)\n        y_seq = y_seq.to(device)\n        edge_index = edge_index.to(device)\n\n        T = X_seq.shape[0]\n        hidden = None\n\n        # Process tile in chunks (Truncated BPTT)\n        for t_start in range(0, T, chunk_size):\n            t_end = min(t_start + chunk_size, T)\n            \n            X_chunk = X_seq[t_start:t_end]\n            y_chunk = y_seq[t_start:t_end]\n\n            optimizer.zero_grad()\n\n            logits, hidden = model(X_chunk, edge_index, hidden)\n\n            loss = criterion(\n                logits.reshape(-1),\n                y_chunk.reshape(-1)\n            )\n\n            loss.backward()\n            \n            # Gradient clipping\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            \n            optimizer.step()\n\n            total_loss += loss.item()\n            num_chunks += 1\n            \n            # Detach hidden state to prevent backprop through entire history\n            if hidden is not None:\n                hidden = hidden.detach()\n\n    return total_loss / num_chunks\n\n\n# ======================================================\n# EVALUATION FUNCTION\n# ======================================================\n\ndef evaluate(model, tiles, criterion, device, chunk_size):\n    \"\"\"Evaluate model on validation tiles\"\"\"\n    model.eval()\n    total_loss = 0\n    num_chunks = 0\n    all_preds = []\n    all_targets = []\n\n    with torch.no_grad():\n        for X_seq, y_seq, edge_index in tiles:\n            X_seq = X_seq.to(device)\n            y_seq = y_seq.to(device)\n            edge_index = edge_index.to(device)\n\n            T = X_seq.shape[0]\n            hidden = None\n\n            # Process in chunks\n            for t_start in range(0, T, chunk_size):\n                t_end = min(t_start + chunk_size, T)\n                \n                X_chunk = X_seq[t_start:t_end]\n                y_chunk = y_seq[t_start:t_end]\n\n                logits, hidden = model(X_chunk, edge_index, hidden)\n\n                loss = criterion(\n                    logits.reshape(-1),\n                    y_chunk.reshape(-1)\n                )\n\n                total_loss += loss.item()\n                num_chunks += 1\n\n                # Collect predictions\n                probs = torch.sigmoid(logits)\n                all_preds.append(probs.cpu().numpy().reshape(-1))\n                all_targets.append(y_chunk.cpu().numpy().reshape(-1))\n                \n                if hidden is not None:\n                    hidden = hidden.detach()\n\n    # Concatenate all predictions\n    all_preds = np.concatenate(all_preds)\n    all_targets = np.concatenate(all_targets)\n\n    # Compute metrics\n    avg_loss = total_loss / num_chunks\n    \n    try:\n        roc_auc = roc_auc_score(all_targets, all_preds)\n    except:\n        roc_auc = 0.0\n    \n    try:\n        precision, recall, _ = precision_recall_curve(all_targets, all_preds)\n        pr_auc = auc(recall, precision)\n    except:\n        pr_auc = 0.0\n\n    return {\n        'loss': avg_loss,\n        'roc_auc': roc_auc,\n        'pr_auc': pr_auc\n    }\n\n\n# ======================================================\n# MODEL & OPTIMIZER SETUP\n# ======================================================\n\nprint(\"\\nInitializing model...\")\nmodel = TGNN(\n    node_features=6,\n    hidden_dim=64,\n    gru_hidden_dim=128,\n    num_gnn_layers=2,\n    dropout=0.3\n).to(DEVICE)\n\nnum_params = sum(p.numel() for p in model.parameters())\nprint(f\"Total parameters: {num_params:,}\")\n\n# Choose loss function based on imbalance\nif pos_ratio < 0.01:\n    print(\"\\nUsing Focal Loss (extreme imbalance)\")\n    criterion = FocalLoss(alpha=0.25, gamma=2.0)\nelse:\n    print(\"\\nUsing Weighted BCE Loss\")\n    pos_weight = torch.tensor([neg_ratio / pos_ratio]).to(DEVICE)\n    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\n# Fixed: Removed 'verbose' parameter (not supported in newer PyTorch)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.5, patience=2\n)\n\n\n# ======================================================\n# TRAINING LOOP\n# ======================================================\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"STARTING TRAINING\")\nprint(\"=\" * 60)\n\nbest_val_loss = float('inf')\npatience_counter = 0\ncurrent_lr = LR\n\nfor epoch in range(EPOCHS):\n    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n    print(\"-\" * 60)\n\n    # Training\n    train_loss = train_epoch(\n        model, train_tiles, criterion, optimizer, DEVICE, CHUNK\n    )\n\n    # Validation\n    val_metrics = evaluate(\n        model, val_tiles, criterion, DEVICE, CHUNK\n    )\n\n    # Learning rate scheduling\n    old_lr = optimizer.param_groups[0]['lr']\n    scheduler.step(val_metrics['loss'])\n    new_lr = optimizer.param_groups[0]['lr']\n    \n    # Manual verbose output for LR changes\n    if old_lr != new_lr:\n        print(f\"Learning rate reduced: {old_lr:.6f} -> {new_lr:.6f}\")\n\n    # Print metrics\n    print(f\"Train Loss: {train_loss:.4f}\")\n    print(f\"Val Loss:   {val_metrics['loss']:.4f}\")\n    print(f\"Val ROC-AUC: {val_metrics['roc_auc']:.4f}\")\n    print(f\"Val PR-AUC:  {val_metrics['pr_auc']:.4f}\")\n\n    # Save best model\n    if val_metrics['loss'] < best_val_loss:\n        best_val_loss = val_metrics['loss']\n        patience_counter = 0\n        \n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'val_loss': val_metrics['loss'],\n            'val_roc_auc': val_metrics['roc_auc'],\n            'val_pr_auc': val_metrics['pr_auc'],\n        }, 'best_tgnn.pt')\n        \n        print(\"✓ Best model saved!\")\n    else:\n        patience_counter += 1\n        print(f\"No improvement. Patience: {patience_counter}/{PATIENCE}\")\n\n    # Early stopping\n    if patience_counter >= PATIENCE:\n        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n        break\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TRAINING COMPLETE\")\nprint(\"=\" * 60)\nprint(f\"Best validation loss: {best_val_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T20:35:31.797673Z","iopub.execute_input":"2026-02-11T20:35:31.797973Z","iopub.status.idle":"2026-02-11T20:52:50.917851Z","shell.execute_reply.started":"2026-02-11T20:35:31.797950Z","shell.execute_reply":"2026-02-11T20:52:50.916948Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n============================================================\n\nLoading tiles...\nTotal tiles loaded: 130\n\nDataset split:\n  Train tiles: 104\n  Val tiles:   26\n\nAnalyzing class distribution...\nPositive ratio: 0.4166%\nNegative ratio: 99.5834%\nImbalance ratio: 239.06:1\n\nInitializing model...\nTotal parameters: 93,889\n\nUsing Focal Loss (extreme imbalance)\n\n============================================================\nSTARTING TRAINING\n============================================================\n\nEpoch 1/10\n------------------------------------------------------------\nTrain Loss: 0.0031\nVal Loss:   0.0020\nVal ROC-AUC: 0.8522\nVal PR-AUC:  0.0221\n✓ Best model saved!\n\nEpoch 2/10\n------------------------------------------------------------\nTrain Loss: 0.0024\nVal Loss:   0.0020\nVal ROC-AUC: 0.8595\nVal PR-AUC:  0.0223\n✓ Best model saved!\n\nEpoch 3/10\n------------------------------------------------------------\nTrain Loss: 0.0023\nVal Loss:   0.0020\nVal ROC-AUC: 0.8598\nVal PR-AUC:  0.0227\n✓ Best model saved!\n\nEpoch 4/10\n------------------------------------------------------------\nTrain Loss: 0.0022\nVal Loss:   0.0020\nVal ROC-AUC: 0.8589\nVal PR-AUC:  0.0232\nNo improvement. Patience: 1/3\n\nEpoch 5/10\n------------------------------------------------------------\nTrain Loss: 0.0021\nVal Loss:   0.0020\nVal ROC-AUC: 0.8614\nVal PR-AUC:  0.0236\n✓ Best model saved!\n\nEpoch 6/10\n------------------------------------------------------------\nTrain Loss: 0.0021\nVal Loss:   0.0020\nVal ROC-AUC: 0.8646\nVal PR-AUC:  0.0264\n✓ Best model saved!\n\nEpoch 7/10\n------------------------------------------------------------\nTrain Loss: 0.0021\nVal Loss:   0.0020\nVal ROC-AUC: 0.8664\nVal PR-AUC:  0.0267\nNo improvement. Patience: 1/3\n\nEpoch 8/10\n------------------------------------------------------------\nTrain Loss: 0.0021\nVal Loss:   0.0020\nVal ROC-AUC: 0.8614\nVal PR-AUC:  0.0266\nNo improvement. Patience: 2/3\n\nEpoch 9/10\n------------------------------------------------------------\nTrain Loss: 0.0020\nVal Loss:   0.0020\nVal ROC-AUC: 0.8642\nVal PR-AUC:  0.0467\n✓ Best model saved!\n\nEpoch 10/10\n------------------------------------------------------------\nTrain Loss: 0.0020\nVal Loss:   0.0020\nVal ROC-AUC: 0.8629\nVal PR-AUC:  0.0281\nNo improvement. Patience: 1/3\n\n============================================================\nTRAINING COMPLETE\n============================================================\nBest validation loss: 0.0020\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}